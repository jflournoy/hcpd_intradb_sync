{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from copy import copy\n",
    "from hashlib import md5\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import yaxil\n",
    "from yaxil.exceptions import RestApiError\n",
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "MAX_RETRIES = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/net/holynfs01/srv/export/ncf_hcp/share_root/data/intradb_jf_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Download from Remote XNAT')\n",
    "parser.add_argument('project', nargs=1)\n",
    "parser.add_argument('--project', '-p', type=str)\n",
    "parser.add_argument('--collections', '-c', type=str, nargs='+')\n",
    "parser.add_argument('--ignore-list', type=list, default=['OTHER_FILES'])\n",
    "parser.add_argument('--subjects', '-s', type=str, default=[], nargs='+', help='Explicit list of subjects')\n",
    "parser.add_argument('--sessions', type=list, default=[], help='Explicit list of sessions')\n",
    "\n",
    "\n",
    "args = parser.parse_args(['CCF_HCD_STG', '-s', 'HCD0015417', 'HCD0021614', 'HCD0022919', '-c', 'Structural_preproc'])\n",
    "opts = vars(args)\n",
    "\n",
    "project=opts.get('project')\n",
    "collections=opts.get('collections')\n",
    "ignore_list=opts.get('ignore_list')\n",
    "subjects=opts.get('subjects')\n",
    "sessions=[]\n",
    "print(opts, project, collections, ignore_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = yaxil.auth('intradb')\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_labels=subjects\n",
    "print(subject_labels)\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with yaxil.session(auth) as sess:\n",
    "     if len(subject_labels):\n",
    "        experiments = []\n",
    "        try:\n",
    "            for label in subject_labels:\n",
    "                sub = list(sess.subjects(label=label, project=project))[0]\n",
    "                experiments.extend(sess.experiments(subject=sub))\n",
    "        except Exception as err:\n",
    "            print('Error with subject {}'.format(label))\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_info=experiments[0]._asdict()\n",
    "exp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with yaxil.session(auth) as sess:\n",
    "    logger.info('Syncing experiment {}'.format(exp_info['label']))\n",
    "    start_time = time.time()\n",
    "    resources_url_pat = ('data/projects/{project}/subjects/{subject_label}/'\n",
    "                         'experiments/{label}/resources')\n",
    "    base_url = resources_url_pat.format(**exp_info)\n",
    "    _, response = yaxil._get(sess._auth, base_url, yaxil.Format.JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = [\n",
    "    result for result in response['ResultSet']['Result']\n",
    "    if result['label'] in collections\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "always_checksum=False\n",
    "resource_info = resources[0]\n",
    "resource_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_cookie = os.path.join(exp_info['label'], resource_info['label'],\n",
    "                                  'SUCCESS')\n",
    "success_cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(success_cookie) and not always_checksum\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_url_pat = (\n",
    "        'data/projects/{project}/subjects/{subject_label}/'\n",
    "        'experiments/{label}/resources/{xnat_abstractresource_id}/files')\n",
    "url_info = copy(exp_info)  # Combine resource and experiment\n",
    "url_info['xnat_abstractresource_id'] = resource_info[\n",
    "        'xnat_abstractresource_id']\n",
    "url_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = resource_url_pat.format(**url_info)\n",
    "_, response = yaxil._get(sess._auth, base_url, yaxil.Format.JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = response['ResultSet']['Result']\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not len(filelist):\n",
    "    raise ValueError('No files could be read from {} in json response: {}'.format(base_url, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = [\n",
    "    file for file in filelist\n",
    "    if file['Name'] in ['probmap_547.nii.gz']\n",
    "]\n",
    "atestfile=test_file[0]\n",
    "atestfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atestfile['uri'] = atestfile.pop('URI')\n",
    "atestfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(sess, out_dir=exp_info['label'], **atestfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(sess,\n",
    "                  uri,\n",
    "                  digest,\n",
    "                  collection,\n",
    "                  out_dir='.',\n",
    "                  overwrite=False,\n",
    "                  **kwargs):\n",
    "    basename = uri.split('files/')[-1]\n",
    "    fname = os.path.join(out_dir, collection, basename)\n",
    "    dirname = os.path.dirname(fname)\n",
    "\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname, 'rb') as f:\n",
    "            disk_digest = md5(f.read()).hexdigest()\n",
    "        if disk_digest == digest:\n",
    "            logger.debug('Digest matched - Skipping {}'.format(fname))\n",
    "            return\n",
    "        elif overwrite:\n",
    "            # import pdb; pdb.set_trace()\n",
    "            logger.info(\n",
    "                'Digest failed - removing {} and trying again'.format(fname))\n",
    "            os.remove(fname)\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                '{} exisited with incorrect digest '.format(fname) +\n",
    "                'but cowardly moving on')\n",
    "\n",
    "    try:\n",
    "        _, result = yaxil._get(\n",
    "            sess._auth,\n",
    "            uri,\n",
    "            yaxil.Format.JSON,  # Format is ignored for _file_ downloads\n",
    "            autobox=False)\n",
    "    except RestApiError as err:\n",
    "        # Empty responses are acceptable for some scripts and onset files\n",
    "        if 'response is empty' in str(err):\n",
    "            result = bytes('', 'utf8')\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(result)\n",
    "\n",
    "    with open(fname, 'rb') as f:\n",
    "        disk_digest = md5(f.read()).hexdigest()\n",
    "    if disk_digest != digest:\n",
    "        retries = kwargs.get('retries', 0)\n",
    "        if overwrite:\n",
    "            os.remove(fname)\n",
    "        if retries >= MAX_RETRIES:\n",
    "            raise RuntimeError(\n",
    "                'Digest failed - ' +\n",
    "                '{} may need to be re-downloaded.'.format(fname))\n",
    "        else:\n",
    "            retries += 1\n",
    "            download_file(sess,\n",
    "                          uri,\n",
    "                          digest,\n",
    "                          collection,\n",
    "                          out_dir,\n",
    "                          overwrite=True,\n",
    "                          retries=retries)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(a, n):\n",
    "    # https://stackoverflow.com/a/2135920\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)]\n",
    "            for i in range(n))\n",
    "\n",
    "for part in split(['1', '2', '3', '4'], 2):\n",
    "    cmd=['sbatch']\n",
    "    cmd+= [os.getcwd() + '/download.sh', ' '.join(part),]\n",
    "    print(' '.join(cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(project, collections, ignore_list=[], subjects=[], sessions=[]):\n",
    "    auth = yaxil.auth('intradb')  # Requires setup and description\n",
    "    start_time = time.time()\n",
    "    with yaxil.session(auth) as sess:\n",
    "        if not sessions:\n",
    "            experiments = fetch_experiments(sess, project, subjects)\n",
    "\n",
    "        for exp_info in [e._asdict() for e in experiments]:\n",
    "            try:\n",
    "                fetch_experiment(sess, collections, exp_info)\n",
    "            except Exception as err:\n",
    "                logger.error('Error with subject {}'.format(exp_info['label']))\n",
    "                continue\n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info('Finished {} experiments in {}'.format(\n",
    "        len(experiments), time.strftime(\"%H:%M:%S\",\n",
    "                                        time.gmtime(elapsed_time))))\n",
    "\n",
    "\n",
    "def fetch_experiments(sess, project, subject_labels):\n",
    "    \"\"\"Fetch a list of yaxil.Experiment's (or get all for a project).\"\"\"\n",
    "    logger.info('Fetching list of experiments')\n",
    "    if len(subject_labels):\n",
    "        experiments = []\n",
    "        try:\n",
    "            for label in subject_labels:\n",
    "                sub = list(sess.subjects(label=label, project=project))[0]\n",
    "                experiments.extend(sess.experiments(subject=sub))\n",
    "        except Exception as err:\n",
    "            print('Error with subject {}'.format(label))\n",
    "            print(err)\n",
    "    else:\n",
    "        experiments = list(sess.experiments(project=project))\n",
    "    logger.info('Found {} experiments'.format(len(experiments)))\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    1/0\n",
    "except Exception as err:\n",
    "    print('division by zero' in str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_experiment(sess, collections, exp_info):\n",
    "    logger.info('Syncing experiment {}'.format(exp_info['label']))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # auth = yaxil.XnatAuth(url='...', username='...', password='...')\n",
    "\n",
    "    # url = 'data/experiments/HCPIntradb02_E08367/files'  # ?format=json'\n",
    "    # exp_info = dict(\n",
    "    #     project='CCF_HCD_STG',\n",
    "    #     subject_label='HCD0021614',\n",
    "    #     label='HCD0021614_V1_MR')  # experiment_label\n",
    "\n",
    "    try:\n",
    "        resources = fetch_resources(sess, exp_info, collections)\n",
    "    except ValueError:\n",
    "        logger.error('Unrecoverable error in {}'.format(exp_info['label']))\n",
    "        resources = []\n",
    "\n",
    "    resource_errors = []\n",
    "\n",
    "    for resource in resources:\n",
    "        try:\n",
    "            fetch_resource(sess, exp_info, resource, always_checksum=True)\n",
    "        except ValueError as err:\n",
    "            if 'No JSON object could be decoded' in err.message:\n",
    "                logger.error(err)\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        except ConnectionError as err:\n",
    "            logger.error(err)\n",
    "            resource_errors.append('ConnectionError: {}'.format(\n",
    "                exp_info['label']))\n",
    "            continue\n",
    "\n",
    "    with open('errors.log', 'a') as f:\n",
    "        f.writelines(resource_errors)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info('Finished experiment {} in {}'.format(\n",
    "        exp_info['label'], time.strftime(\"%H:%M:%S\",\n",
    "                                         time.gmtime(elapsed_time))))\n",
    "\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    # url_pat = ('data/projects/{project}/subjects/{subject_label}/experiments/'\n",
    "    #            '{label}/files')\n",
    "    #\n",
    "    # base_url = url_pat.format(**exp_info)\n",
    "    # logger.info('Syncing {}'.format(base_url))\n",
    "\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    # # sess.get(base_url, yaxil.Format.JSON)\n",
    "    # _, response = yaxil._get(sess._auth, base_url, yaxil.Format.JSON)\n",
    "    #\n",
    "    # for collection in collections:\n",
    "    #     import pdb\n",
    "    #     pdb.set_trace()\n",
    "    #     logger.info('Downloading {}'.format(collection))\n",
    "    #     filelist = [\n",
    "    #         r for r in response['ResultSet']['Result']\n",
    "    #         if r['collection'] == collection\n",
    "    #     ]\n",
    "\n",
    "\n",
    "def fetch_resources(sess, exp_info, collections=None):\n",
    "    \"\"\"Fetch a list of json resources with collection label and id.\"\"\"\n",
    "\n",
    "    resources_url_pat = ('data/projects/{project}/subjects/{subject_label}/'\n",
    "                         'experiments/{label}/resources')\n",
    "    base_url = resources_url_pat.format(**exp_info)\n",
    "    _, response = yaxil._get(sess._auth, base_url, yaxil.Format.JSON)\n",
    "\n",
    "    # Filter only wanted collections or return all\n",
    "    if collections:\n",
    "        resources = [\n",
    "            result for result in response['ResultSet']['Result']\n",
    "            if result['label'] in collections\n",
    "        ]\n",
    "    else:\n",
    "        resources = response['ResultSet']['Result']\n",
    "\n",
    "    if not len(resources):\n",
    "        msg = 'Found no resources '\n",
    "        if collections:\n",
    "            msg += 'matching collections {}'.format(collections)\n",
    "        msg += 'for {}'.format(resources_url_pat)\n",
    "        logger.warning(msg)\n",
    "\n",
    "    return resources\n",
    "\n",
    "\n",
    "def fetch_resource(sess, exp_info, resource_info, always_checksum=False):\n",
    "    # Use a cookie to mark a resource as complete\n",
    "    success_cookie = os.path.join(exp_info['label'], resource_info['label'],\n",
    "                                  'SUCCESS')\n",
    "    if os.path.exists(success_cookie) and not always_checksum:\n",
    "        return\n",
    "\n",
    "    resource_url_pat = (\n",
    "        'data/projects/{project}/subjects/{subject_label}/'\n",
    "        'experiments/{label}/resources/{xnat_abstractresource_id}/files')\n",
    "    url_info = copy(exp_info)  # Combine resource and experiment\n",
    "    url_info['xnat_abstractresource_id'] = resource_info[\n",
    "        'xnat_abstractresource_id']\n",
    "\n",
    "    base_url = resource_url_pat.format(**url_info)\n",
    "    _, response = yaxil._get(sess._auth, base_url, yaxil.Format.JSON)\n",
    "\n",
    "    filelist = response['ResultSet']['Result']\n",
    "    if not len(filelist):\n",
    "        raise ValueError('No files could be read from {} in json response: {}'.format(base_url, response))\n",
    "    logger.info('Syncing {} file (resources) from {}'.format(len(filelist), base_url))\n",
    "\n",
    "    start_time = time.time()\n",
    "    for fileinfo in filelist:\n",
    "        try:\n",
    "            # Rename URI (python variable case)\n",
    "            fileinfo['uri'] = fileinfo.pop('URI')\n",
    "            if ignore_file(fileinfo['uri'], ignore_list):\n",
    "                logger.debug('Ignoring {}'.format(fileinfo['uri']))\n",
    "                continue\n",
    "            download_file(sess, out_dir=exp_info['label'], **fileinfo)\n",
    "        except RuntimeError:\n",
    "            logger.info('Digest failed on {}'.format(fileinfo['uri']))\n",
    "        except RestApiError as err:\n",
    "            logger.info('Download Error on {}: {}'.format(\n",
    "                fileinfo['uri'], err))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info('Finished in {}'.format(\n",
    "        time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))\n",
    "\n",
    "    # if we got here, mark this collection as completed (\"touch\" cookie)\n",
    "    open(success_cookie, 'w').close()\n",
    "\n",
    "\n",
    "def download_file(sess,\n",
    "                  uri,\n",
    "                  digest,\n",
    "                  collection,\n",
    "                  out_dir='.',\n",
    "                  overwrite=False,\n",
    "                  **kwargs):\n",
    "    basename = uri.split('files/')[-1]\n",
    "    fname = os.path.join(out_dir, collection, basename)\n",
    "    dirname = os.path.dirname(fname)\n",
    "\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname, 'rb') as f:\n",
    "            disk_digest = md5(f.read()).hexdigest()\n",
    "        if disk_digest == digest:\n",
    "            logger.debug('Digest matched - Skipping {}'.format(fname))\n",
    "            return\n",
    "        elif overwrite:\n",
    "            # import pdb; pdb.set_trace()\n",
    "            logger.info(\n",
    "                'Digest failed - removing {} and trying again'.format(fname))\n",
    "            os.remove(fname)\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                '{} exisited with incorrect digest '.format(fname) +\n",
    "                'but cowardly moving on')\n",
    "\n",
    "    try:\n",
    "        _, result = yaxil._get(\n",
    "            sess._auth,\n",
    "            uri,\n",
    "            yaxil.Format.JSON,  # Format is ignored for _file_ downloads\n",
    "            autobox=False)\n",
    "    except RestApiError as err:\n",
    "        # Empty responses are acceptable for some scripts and onset files\n",
    "        if 'response is empty' in err.message:\n",
    "            result = bytes('')\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(result)\n",
    "\n",
    "    with open(fname, 'rb') as f:\n",
    "        disk_digest = md5(f.read()).hexdigest()\n",
    "    if disk_digest != digest:\n",
    "        retries = kwargs.get('retries', 0)\n",
    "        if overwrite:\n",
    "            os.remove(fname)\n",
    "        if retries >= MAX_RETRIES:\n",
    "            raise RuntimeError(\n",
    "                'Digest failed - ' +\n",
    "                '{} may need to be re-downloaded.'.format(fname))\n",
    "        else:\n",
    "            retries += 1\n",
    "            download_file(sess,\n",
    "                          uri,\n",
    "                          digest,\n",
    "                          collection,\n",
    "                          out_dir,\n",
    "                          overwrite=True,\n",
    "                          retries=retries)\n",
    "\n",
    "\n",
    "def ignore_file(uri, ignores_list):\n",
    "    ignore = False\n",
    "    for ignore_pat in ignores_list:\n",
    "        if re.search(ignore_pat, uri):\n",
    "            ignore = True\n",
    "    return ignore\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Download from Remote XNAT')\n",
    "    parser.add_argument('project', nargs=1)\n",
    "    parser.add_argument('--project', '-p', type=str)\n",
    "    parser.add_argument('--collections', '-c', type=str, nargs='+')\n",
    "    parser.add_argument('--ignore-list', type=list, default=['OTHER_FILES'])\n",
    "    parser.add_argument('--subjects', '-s', type=list, default=[], help='Explicit list of subjects')\n",
    "    parser.add_argument('--sessions', type=list, default=[], help='Explicit list of sessions')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # usage: ./download_resources.py CCF_HCD_STG\n",
    "    args = parse_args()\n",
    "\n",
    "    # collections = [\n",
    "    #     #'Diffusion_unproc',\n",
    "    #     #'mbPCASLhr_unproc',\n",
    "    #     # 'rfMRI_REST1_AP_unproc',\n",
    "    #     # 'rfMRI_REST1_PA_unproc',\n",
    "    #     # 'rfMRI_REST2_AP_unproc',\n",
    "    #     # 'rfMRI_REST2_PA_unproc',\n",
    "    #     'Structural_preproc',\n",
    "    #     #       'T1w_MPR_vNav_4e_RMS_unproc',\n",
    "    #     #       'T2w_SPC_vNav_unproc',\n",
    "    #     #       'tfMRI_GUESSING_PA_unproc',\n",
    "    #     #       'tfMRI_GUESSING_AP_unproc',\n",
    "    #     #       'tfMRI_CARIT_AP_unproc',\n",
    "    #     #       'tfMRI_CARIT_PA_unproc',\n",
    "    #     #       'tfMRI_EMOTION_PA_unproc',\n",
    "    # ]\n",
    "\n",
    "    opts = vars(args)\n",
    "    main(**opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hcpl]",
   "language": "python",
   "name": "conda-env-.conda-hcpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
